{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>LW</th>\n",
       "      <th>Saenger</th>\n",
       "      <th>Can</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.067949</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.060256</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.134211</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>cWW</td>\n",
       "      <td>19-XIX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.040975</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.035437</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>0.036545</td>\n",
       "      <td>0.034330</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.071146</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>cWW</td>\n",
       "      <td>19-XIX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039489</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.076316</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>cWW</td>\n",
       "      <td>20-XX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049942</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>cWW</td>\n",
       "      <td>20-XX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.040975</td>\n",
       "      <td>0.040975</td>\n",
       "      <td>0.027685</td>\n",
       "      <td>0.042082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.041502</td>\n",
       "      <td>0.397233</td>\n",
       "      <td>cWW</td>\n",
       "      <td>19-XIX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4         5         6         7  \\\n",
       "0  0.055128  0.0  0.015385  0.067949  0.024359  0.020513  0.060256  0.028205   \n",
       "1  0.050941  0.0  0.046512  0.040975  0.023256  0.035437  0.037652  0.036545   \n",
       "2  0.052265  0.0  0.039489  0.045296  0.022067  0.032520  0.040650  0.034843   \n",
       "3  0.052265  0.0  0.049942  0.038328  0.022067  0.041812  0.034843  0.037166   \n",
       "4  0.050941  0.0  0.048726  0.037652  0.023256  0.033223  0.040975  0.040975   \n",
       "\n",
       "          8         9  ...       143       144       145       146       147  \\\n",
       "0  0.032051  0.030769  ...  0.002632  0.010526  0.015789  0.134211  0.278947   \n",
       "1  0.034330  0.037652  ...  0.000000  0.003953  0.007905  0.015810  0.071146   \n",
       "2  0.038328  0.038328  ...  0.000000  0.002632  0.076316  0.347368  0.007895   \n",
       "3  0.032520  0.041812  ...  0.002632  0.050000  0.373684  0.007895  0.000000   \n",
       "4  0.027685  0.042082  ...  0.001976  0.000000  0.005929  0.000000  0.005929   \n",
       "\n",
       "        148       149   LW  Saenger   Can  \n",
       "0  0.000000  0.002632  cWW   19-XIX  True  \n",
       "1  0.343874  0.009881  cWW   19-XIX  True  \n",
       "2  0.002632  0.002632  cWW    20-XX  True  \n",
       "3  0.000000  0.002632  cWW    20-XX  True  \n",
       "4  0.041502  0.397233  cWW   19-XIX  True  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"full_data_50.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['LW', 'Can', 'Saenger'], axis=1)\n",
    "y_canonical = data['Can']\n",
    "y_saenger = data['Saenger']\n",
    "y_lw = data['LW'] # cannonical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9858918663168308\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98     18596\n",
      "        True       0.98      0.99      0.99     27902\n",
      "\n",
      "    accuracy                           0.99     46498\n",
      "   macro avg       0.99      0.98      0.99     46498\n",
      "weighted avg       0.99      0.99      0.99     46498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "y_labeled = label_encoder.fit_transform(y_canonical)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=2137)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "predictions = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9522775173125726\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          --       0.91      0.95      0.93     11475\n",
      "        01-I       0.92      0.92      0.92       166\n",
      "       02-II       0.95      0.93      0.94       341\n",
      "      03-III       1.00      0.77      0.87        26\n",
      "       04-IV       0.89      0.59      0.71        94\n",
      "        05-V       0.92      0.84      0.88       251\n",
      "       06-VI       0.99      0.78      0.87       277\n",
      "      07-VII       0.98      0.59      0.74        78\n",
      "     08-VIII       0.89      0.93      0.91       382\n",
      "       09-IX       1.00      0.28      0.44        25\n",
      "        10-X       0.95      0.60      0.74       309\n",
      "       11-XI       0.97      0.96      0.97      2550\n",
      "      12-XII       1.00      0.30      0.46        10\n",
      "     13-XIII       0.97      0.72      0.83        47\n",
      "      14-XIV       1.00      0.75      0.86        12\n",
      "       15-XV       0.00      0.00      0.00         2\n",
      "      16-XVI       0.92      0.85      0.88       318\n",
      "     17-XVII       1.00      0.75      0.86         4\n",
      "    18-XVIII       0.93      0.64      0.76        61\n",
      "      19-XIX       0.97      0.99      0.98     19509\n",
      "       20-XX       0.97      0.99      0.98      5498\n",
      "      21-XXI       1.00      0.56      0.72       179\n",
      "     22-XXII       1.00      0.39      0.56       124\n",
      "    23-XXIII       1.00      0.70      0.83       280\n",
      "     24-XXIV       0.96      0.95      0.96      1213\n",
      "      25-XXV       0.99      0.62      0.76       282\n",
      "     26-XXVI       1.00      0.46      0.63        37\n",
      "    27-XXVII       0.00      0.00      0.00         4\n",
      "   28-XXVIII       0.94      0.89      0.92      2895\n",
      "     29-XXIX       1.00      0.45      0.62        49\n",
      "\n",
      "    accuracy                           0.95     46498\n",
      "   macro avg       0.90      0.67      0.75     46498\n",
      "weighted avg       0.95      0.95      0.95     46498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "y_labeled = label_encoder.fit_transform(y_saenger)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=2137)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "predictions = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leontis-Westhof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9525570992300744\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cHH       0.95      0.56      0.71       175\n",
      "         cHS       0.88      0.94      0.91      1279\n",
      "         cHW       0.89      0.76      0.82      1243\n",
      "         cSS       0.87      0.95      0.91       961\n",
      "         cWS       0.86      0.84      0.85      1826\n",
      "         cWW       0.98      1.00      0.99     30272\n",
      "         tHH       0.95      0.81      0.87       612\n",
      "         tHS       0.93      0.95      0.94      3377\n",
      "         tHW       0.89      0.93      0.91      2864\n",
      "         tSS       0.88      0.95      0.91      1193\n",
      "         tWS       0.85      0.78      0.82      1681\n",
      "         tWW       0.96      0.64      0.77      1015\n",
      "\n",
      "    accuracy                           0.95     46498\n",
      "   macro avg       0.91      0.84      0.87     46498\n",
      "weighted avg       0.95      0.95      0.95     46498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "y_labeled = label_encoder.fit_transform(y_lw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=2137)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "predictions = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
